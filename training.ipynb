{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"LSTM-v2.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNamKWZ7JoF5cGb5B9i6f/d"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LEUJPQUPtorx","executionInfo":{"status":"ok","timestamp":1655186161449,"user_tz":-420,"elapsed":3049,"user":{"displayName":"Zaki Indra Yudhistira","userId":"04720182422086656571"}},"outputId":"52a5ac9d-f452-40f6-86c2-6a586066a329"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n","  import pandas.util.testing as tm\n"]}],"source":["import pandas as pd\n","import numpy as np\n","import statsmodels.api as sm\n","\n","import matplotlib as mpl\n","import matplotlib.pyplot as plt\n","\n","import tensorflow as tf\n","import keras\n","\n","from tqdm import tqdm\n","\n","BATCH_SIZE = 16\n","\n","# source: https://www.tensorflow.org/tutorials/structured_data/time_series\n","class WindowGenerator():\n","    def __init__(self, input_width, label_width, shift,\n","                 train_df=None, val_df=None, test_df=None,\n","                 label_columns=None):\n","        # Store the raw data.\n","        self.train_df = train_df\n","        self.val_df = val_df\n","        self.test_df = test_df\n","\n","        # Work out the label column indices.\n","        self.label_columns = label_columns\n","        if label_columns is not None:\n","            self.label_columns_indices = {name: i for i, name in\n","                                          enumerate(label_columns)}\n","        self.column_indices = {name: i for i, name in\n","                               enumerate(train_df.columns)}\n","\n","        # Work out the window parameters.\n","        self.input_width = input_width\n","        self.label_width = label_width\n","        self.shift = shift\n","\n","        self.total_window_size = input_width + shift\n","\n","        self.input_slice = slice(0, input_width)\n","        self.input_indices = np.arange(self.total_window_size)[\n","            self.input_slice]\n","\n","        self.label_start = self.total_window_size - self.label_width\n","        self.labels_slice = slice(self.label_start, None)\n","        self.label_indices = np.arange(self.total_window_size)[\n","            self.labels_slice]\n","\n","    def __repr__(self):\n","        return '\\n'.join([\n","            f'Total window size: {self.total_window_size}',\n","            f'Input indices: {self.input_indices}',\n","            f'Label indices: {self.label_indices}',\n","            f'Label column name(s): {self.label_columns}'])\n","\n","    def split_window(self, features):\n","        inputs = features[:, self.input_slice, :]\n","        labels = features[:, self.labels_slice, :]\n","        if self.label_columns is not None:\n","            labels = tf.stack(\n","                [labels[:, :, self.column_indices[name]]\n","                    for name in self.label_columns],\n","                axis=-1)\n","\n","        # Slicing doesn't preserve static shape information, so set the shapes\n","        # manually. This way the `tf.data.Datasets` are easier to inspect.\n","        inputs.set_shape([None, self.input_width, None])\n","        labels.set_shape([None, self.label_width, None])\n","\n","        return inputs, labels\n","\n","    def plot(self, model=None, plot_col='sales', max_subplots=3):\n","        inputs, labels = self.example\n","        plt.figure(figsize=(12, 8))\n","        plot_col_index = self.column_indices[plot_col]\n","        max_n = min(max_subplots, len(inputs))\n","        for n in range(max_n):\n","            plt.subplot(max_n, 1, n+1)\n","            plt.ylabel(f'{plot_col} [normed]')\n","            plt.plot(self.input_indices, inputs[n, :, plot_col_index],\n","                     label='Inputs', marker='.', zorder=-10)\n","\n","            if self.label_columns:\n","                label_col_index = self.label_columns_indices.get(\n","                    plot_col, None)\n","            else:\n","                label_col_index = plot_col_index\n","\n","            if label_col_index is None:\n","                continue\n","\n","            plt.scatter(self.label_indices, labels[n, :, label_col_index],\n","                        edgecolors='k', label='Labels', c='#2ca02c', s=64)\n","            if model is not None:\n","                predictions = model(inputs)\n","                plt.scatter(self.label_indices, predictions[n, :, label_col_index],\n","                        marker='X', edgecolors='k', label='Predictions',\n","                        c='#ff7f0e', s=64)\n","\n","            if n == 0:\n","                plt.legend()\n","        plt.xlabel('Time [h]')\n","\n","    def make_dataset(self, data):\n","        data = np.array(data, dtype=np.float32)\n","        ds = tf.keras.utils.timeseries_dataset_from_array(\n","            data=data,\n","            targets=None,\n","            sequence_length=self.total_window_size,\n","            sequence_stride=1,\n","            shuffle=True,\n","            batch_size=32,)\n","\n","        ds = ds.map(self.split_window)\n","\n","        return ds\n","\n","    @property\n","    def train(self):\n","        return self.make_dataset(self.train_df)\n","\n","    @property\n","    def val(self):\n","        return self.make_dataset(self.val_df)\n","\n","    @property\n","    def test(self):\n","        return self.make_dataset(self.test_df)\n","\n","    @property\n","    def example(self):\n","        \"\"\"Get and cache an example batch of `inputs, labels` for plotting.\"\"\"\n","        result = getattr(self, '_example', None)\n","        if result is None:\n","            # No example batch was found, so get one from the `.train` dataset\n","            result = next(iter(self.train))\n","            # And cache it for next time\n","            self._example = result\n","        return result\n","\n","\n","def fourier_transform(dataframe:pd.DataFrame) -> pd.DataFrame:\n","    temp = dataframe.copy()\n","    date_time = pd.to_datetime(temp.pop(\"date\"), format='%Y-%m-%d')\n","\n","    day = 24*60*60\n","    year = (365.2425)*day\n","    \n","    timestamp_s = date_time.map(pd.Timestamp.timestamp)\n","    \n","    temp['Year sin'] = np.sin(timestamp_s * (2 * np.pi / year))\n","    temp['Year cos'] = np.cos(timestamp_s * (2 * np.pi / year))\n","    temp = temp.set_index(date_time)\n","    return temp\n","\n","def make_data(dataframe:pd.DataFrame):\n","    data = fourier_transform(dataframe)\n","    dummy = data.copy().drop(labels=['store', 'item'], axis=1)\n","    window = WindowGenerator(input_width=30, label_width=1, shift=1, train_df=dummy, label_columns=['sales'])\n","    stores = data[\"store\"].unique()\n","\n","    # data\n","    x1 = [[]] # store, item\n","    x2 = np.empty((1, 30, 3)) # sales, year trig\n","    y = np.empty((1, 1, 1))\n","\n","    val1 = [[]] # store, item\n","    val2 = np.empty((1, 30, 3)) # sales, year trig\n","    valy = np.empty((1, 1, 1))\n","\n","    for store in tqdm(stores):\n","        temps = data[(data[\"store\"]==store)]\n","    \n","        items = temps[\"item\"].unique()\n","\n","        for item in items:\n","            temp = temps[(temps[\"item\"]==item)].copy()\n","            temp.drop(labels=[\"store\", \"item\"], axis=1, inplace=True)\n","\n","            length = temp.__len__()\n","            stack = np.empty((1, 31, 3))\n","\n","            for index in range(length - 30):\n","                array = np.array(temp[index:index+31])\n","                stack = np.append(stack, array.reshape(1, -1, 3), 0)\n","\n","            stack = stack[1:, :, :]\n","\n","            stack = tf.convert_to_tensor(stack)\n","            inputs, labels = window.split_window(stack)\n","\n","            shp = inputs.shape[0]\n","            train_size = shp*8//10\n","            val_size = shp - train_size\n","\n","            x1.extend([[store, item]]*train_size)\n","            x2 = tf.concat([x2, inputs[:train_size]], 0)\n","            y = tf.concat([y, labels[:train_size]], 0)\n","\n","            val1.extend([[store, item]]*val_size)\n","            val2 = tf.concat([val2, inputs[train_size:]], 0)\n","            valy = tf.concat([valy, labels[train_size:]], 0)\n","                \n","    x1 = np.array(x1[1:])\n","    x2 = x2.numpy()[1:, :, :]\n","    y = y.numpy()[1:, :, :].reshape(-1, 1)\n","\n","    val1 = np.array(val1[1:])\n","    val2 = val2.numpy()[1:, :, :]\n","    valy = valy.numpy()[1:, :, :].reshape(-1, 1)\n","\n","    train_data = tf.data.Dataset.from_tensor_slices(((x1, x2), y)).batch(BATCH_SIZE)\n","    val_data = tf.data.Dataset.from_tensor_slices(((val1, val2), valy)).batch(valy.shape[0])\n","\n","    return train_data, val_data"]},{"cell_type":"code","source":["import keras\n","\n","TIME_DELAY = 30\n","\n","def create_model() -> keras.Model:\n","    input_1 = keras.Input((2,), name=\"input_1\")\n","    input_2 = keras.Input((TIME_DELAY, 3), name=\"input_2\")\n","    dense = keras.layers.Dense(2)(input_1)\n","    flatten1 = keras.layers.Flatten()(dense)\n","    lstm = keras.layers.LSTM(TIME_DELAY, return_sequences=True)(input_2)\n","    flatten2 = keras.layers.Flatten()(lstm)\n","\n","    concat = keras.layers.concatenate([flatten1, flatten2])\n","    dense = keras.layers.Dense(256, activation=\"relu\")(concat)\n","    dropout = keras.layers.Dropout(0.2)(dense)\n","    dense = keras.layers.Dense(64, activation=\"relu\")(dropout)\n","    dropout = keras.layers.Dropout(0.2)(dense)\n","    output = keras.layers.Dense(1)(dropout)\n","    return keras.Model(inputs=[input_1, input_2], outputs=output)"],"metadata":{"id":"u7c3_Rb1uTwI","executionInfo":{"status":"ok","timestamp":1655186161450,"user_tz":-420,"elapsed":5,"user":{"displayName":"Zaki Indra Yudhistira","userId":"04720182422086656571"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["MAX_EPOCH = 50\n","\n","df = pd.read_csv(\"train.csv\")\n","model = create_model()\n","model.summary()\n","\n","train_data, val_data = make_data(df)\n","\n","early_stopper = tf.keras.callbacks.EarlyStopping(\"val_loss\", 0.1, 4, 1, restore_best_weights=True)\n","reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_delta=0.3, min_lr=0)\n","model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\"tmp/models\", \"val_loss\", 1, True)\n","optimizer = tf.keras.optimizers.Adam()\n","\n","model.compile(optimizer, \"mse\", [\"mse\", \"mae\"])\n","\n","model.fit(train_data, batch_size=BATCH_SIZE, epochs=MAX_EPOCH, \n","          callbacks=[early_stopper, reduce_lr, model_checkpoint], validation_data=val_data)\n","\n","model.evaluate(val_data)\n","\n","model.save('models/my_model.h5')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"39SCSTbXuaaz","executionInfo":{"status":"ok","timestamp":1655192671085,"user_tz":-420,"elapsed":6509640,"user":{"displayName":"Zaki Indra Yudhistira","userId":"04720182422086656571"}},"outputId":"30e4d536-f7f3-428c-89d1-ac6335e01cc8"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_1 (InputLayer)           [(None, 2)]          0           []                               \n","                                                                                                  \n"," input_2 (InputLayer)           [(None, 30, 3)]      0           []                               \n","                                                                                                  \n"," dense (Dense)                  (None, 2)            6           ['input_1[0][0]']                \n","                                                                                                  \n"," lstm (LSTM)                    (None, 30, 30)       4080        ['input_2[0][0]']                \n","                                                                                                  \n"," flatten (Flatten)              (None, 2)            0           ['dense[0][0]']                  \n","                                                                                                  \n"," flatten_1 (Flatten)            (None, 900)          0           ['lstm[0][0]']                   \n","                                                                                                  \n"," concatenate (Concatenate)      (None, 902)          0           ['flatten[0][0]',                \n","                                                                  'flatten_1[0][0]']              \n","                                                                                                  \n"," dense_1 (Dense)                (None, 256)          231168      ['concatenate[0][0]']            \n","                                                                                                  \n"," dropout (Dropout)              (None, 256)          0           ['dense_1[0][0]']                \n","                                                                                                  \n"," dense_2 (Dense)                (None, 64)           16448       ['dropout[0][0]']                \n","                                                                                                  \n"," dropout_1 (Dropout)            (None, 64)           0           ['dense_2[0][0]']                \n","                                                                                                  \n"," dense_3 (Dense)                (None, 1)            65          ['dropout_1[0][0]']              \n","                                                                                                  \n","==================================================================================================\n","Total params: 251,767\n","Trainable params: 251,767\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 10/10 [04:03<00:00, 24.36s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","44873/44875 [============================>.] - ETA: 0s - loss: 133.5685 - mse: 133.5685 - mae: 8.6169\n","Epoch 1: val_loss improved from inf to 133.72977, saving model to tmp/models\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Assets written to: tmp/models/assets\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:Assets written to: tmp/models/assets\n","WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f3a405a7650> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r44875/44875 [==============================] - 245s 5ms/step - loss: 133.5667 - mse: 133.5667 - mae: 8.6168 - val_loss: 133.7298 - val_mse: 133.7298 - val_mae: 8.3998 - lr: 0.0010\n","Epoch 2/50\n","44869/44875 [============================>.] - ETA: 0s - loss: 95.7056 - mse: 95.7056 - mae: 7.3733\n","Epoch 2: val_loss improved from 133.72977 to 121.03506, saving model to tmp/models\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Assets written to: tmp/models/assets\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:Assets written to: tmp/models/assets\n","WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f3a405a7650> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r44875/44875 [==============================] - 240s 5ms/step - loss: 95.7109 - mse: 95.7109 - mae: 7.3735 - val_loss: 121.0351 - val_mse: 121.0351 - val_mae: 8.3791 - lr: 0.0010\n","Epoch 3/50\n","44871/44875 [============================>.] - ETA: 0s - loss: 87.0248 - mse: 87.0248 - mae: 7.0725\n","Epoch 3: val_loss did not improve from 121.03506\n","44875/44875 [==============================] - 239s 5ms/step - loss: 87.0293 - mse: 87.0293 - mae: 7.0728 - val_loss: 134.8712 - val_mse: 134.8712 - val_mae: 8.4527 - lr: 0.0010\n","Epoch 4/50\n","44870/44875 [============================>.] - ETA: 0s - loss: 83.3827 - mse: 83.3827 - mae: 6.9269\n","Epoch 4: val_loss did not improve from 121.03506\n","44875/44875 [==============================] - 231s 5ms/step - loss: 83.3896 - mse: 83.3896 - mae: 6.9272 - val_loss: 134.7981 - val_mse: 134.7981 - val_mae: 8.4696 - lr: 0.0010\n","Epoch 5/50\n","44868/44875 [============================>.] - ETA: 0s - loss: 76.4616 - mse: 76.4616 - mae: 6.6671\n","Epoch 5: val_loss improved from 121.03506 to 97.57976, saving model to tmp/models\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Assets written to: tmp/models/assets\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:Assets written to: tmp/models/assets\n","WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f3a405a7650> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r44875/44875 [==============================] - 231s 5ms/step - loss: 76.4695 - mse: 76.4695 - mae: 6.6674 - val_loss: 97.5798 - val_mse: 97.5798 - val_mae: 7.3084 - lr: 5.0000e-04\n","Epoch 6/50\n","44869/44875 [============================>.] - ETA: 0s - loss: 75.1088 - mse: 75.1088 - mae: 6.5951\n","Epoch 6: val_loss improved from 97.57976 to 94.41442, saving model to tmp/models\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Assets written to: tmp/models/assets\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:Assets written to: tmp/models/assets\n","WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f3a405a7650> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r44875/44875 [==============================] - 229s 5ms/step - loss: 75.1142 - mse: 75.1142 - mae: 6.5954 - val_loss: 94.4144 - val_mse: 94.4144 - val_mae: 7.2182 - lr: 5.0000e-04\n","Epoch 7/50\n","44874/44875 [============================>.] - ETA: 0s - loss: 73.7160 - mse: 73.7160 - mae: 6.5286\n","Epoch 7: val_loss improved from 94.41442 to 94.27973, saving model to tmp/models\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Assets written to: tmp/models/assets\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:Assets written to: tmp/models/assets\n","WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f3a405a7650> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r44875/44875 [==============================] - 231s 5ms/step - loss: 73.7162 - mse: 73.7162 - mae: 6.5287 - val_loss: 94.2797 - val_mse: 94.2797 - val_mae: 7.2143 - lr: 5.0000e-04\n","Epoch 8/50\n","44871/44875 [============================>.] - ETA: 0s - loss: 72.6913 - mse: 72.6913 - mae: 6.4853\n","Epoch 8: val_loss did not improve from 94.27973\n","44875/44875 [==============================] - 226s 5ms/step - loss: 72.6920 - mse: 72.6920 - mae: 6.4853 - val_loss: 110.1761 - val_mse: 110.1761 - val_mae: 7.6381 - lr: 5.0000e-04\n","Epoch 9/50\n","44867/44875 [============================>.] - ETA: 0s - loss: 71.1578 - mse: 71.1578 - mae: 6.4230\n","Epoch 9: val_loss improved from 94.27973 to 80.76264, saving model to tmp/models\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Assets written to: tmp/models/assets\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:Assets written to: tmp/models/assets\n","WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f3a405a7650> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r44875/44875 [==============================] - 230s 5ms/step - loss: 71.1658 - mse: 71.1658 - mae: 6.4234 - val_loss: 80.7626 - val_mse: 80.7626 - val_mae: 6.8214 - lr: 2.5000e-04\n","Epoch 10/50\n","44875/44875 [==============================] - ETA: 0s - loss: 70.5396 - mse: 70.5396 - mae: 6.4007\n","Epoch 10: val_loss improved from 80.76264 to 80.71609, saving model to tmp/models\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Assets written to: tmp/models/assets\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:Assets written to: tmp/models/assets\n","WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f3a405a7650> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r44875/44875 [==============================] - 231s 5ms/step - loss: 70.5396 - mse: 70.5396 - mae: 6.4007 - val_loss: 80.7161 - val_mse: 80.7161 - val_mae: 6.8053 - lr: 2.5000e-04\n","Epoch 11/50\n","44865/44875 [============================>.] - ETA: 0s - loss: 70.1414 - mse: 70.1414 - mae: 6.3840\n","Epoch 11: val_loss improved from 80.71609 to 80.07367, saving model to tmp/models\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Assets written to: tmp/models/assets\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:Assets written to: tmp/models/assets\n","WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f3a405a7650> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r44875/44875 [==============================] - 229s 5ms/step - loss: 70.1514 - mse: 70.1514 - mae: 6.3845 - val_loss: 80.0737 - val_mse: 80.0737 - val_mae: 6.7757 - lr: 2.5000e-04\n","Epoch 12/50\n","44870/44875 [============================>.] - ETA: 0s - loss: 70.0147 - mse: 70.0147 - mae: 6.3742\n","Epoch 12: val_loss did not improve from 80.07367\n","44875/44875 [==============================] - 226s 5ms/step - loss: 70.0190 - mse: 70.0190 - mae: 6.3744 - val_loss: 80.6880 - val_mse: 80.6880 - val_mae: 6.7996 - lr: 2.5000e-04\n","Epoch 13/50\n","44869/44875 [============================>.] - ETA: 0s - loss: 69.8272 - mse: 69.8272 - mae: 6.3684\n","Epoch 13: val_loss did not improve from 80.07367\n","44875/44875 [==============================] - 227s 5ms/step - loss: 69.8314 - mse: 69.8314 - mae: 6.3686 - val_loss: 80.1162 - val_mse: 80.1162 - val_mae: 6.8013 - lr: 2.5000e-04\n","Epoch 14/50\n","44871/44875 [============================>.] - ETA: 0s - loss: 68.8399 - mse: 68.8399 - mae: 6.3339\n","Epoch 14: val_loss improved from 80.07367 to 76.46053, saving model to tmp/models\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Assets written to: tmp/models/assets\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:Assets written to: tmp/models/assets\n","WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f3a405a7650> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r44875/44875 [==============================] - 231s 5ms/step - loss: 68.8402 - mse: 68.8402 - mae: 6.3339 - val_loss: 76.4605 - val_mse: 76.4605 - val_mae: 6.6726 - lr: 1.2500e-04\n","Epoch 15/50\n","44869/44875 [============================>.] - ETA: 0s - loss: 68.9195 - mse: 68.9195 - mae: 6.3339\n","Epoch 15: val_loss improved from 76.46053 to 75.70903, saving model to tmp/models\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Assets written to: tmp/models/assets\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:Assets written to: tmp/models/assets\n","WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f3a405a7650> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r44875/44875 [==============================] - 227s 5ms/step - loss: 68.9231 - mse: 68.9231 - mae: 6.3341 - val_loss: 75.7090 - val_mse: 75.7090 - val_mae: 6.6558 - lr: 1.2500e-04\n","Epoch 16/50\n","44869/44875 [============================>.] - ETA: 0s - loss: 68.4985 - mse: 68.4985 - mae: 6.3183\n","Epoch 16: val_loss did not improve from 75.70903\n","44875/44875 [==============================] - 224s 5ms/step - loss: 68.5032 - mse: 68.5032 - mae: 6.3186 - val_loss: 77.6146 - val_mse: 77.6146 - val_mae: 6.7167 - lr: 1.2500e-04\n","Epoch 17/50\n","44866/44875 [============================>.] - ETA: 0s - loss: 68.3528 - mse: 68.3528 - mae: 6.3112\n","Epoch 17: val_loss did not improve from 75.70903\n","44875/44875 [==============================] - 223s 5ms/step - loss: 68.3598 - mse: 68.3598 - mae: 6.3116 - val_loss: 76.5762 - val_mse: 76.5762 - val_mae: 6.6785 - lr: 1.2500e-04\n","Epoch 18/50\n","44870/44875 [============================>.] - ETA: 0s - loss: 68.2006 - mse: 68.2006 - mae: 6.3040\n","Epoch 18: val_loss improved from 75.70903 to 75.21457, saving model to tmp/models\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Assets written to: tmp/models/assets\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:Assets written to: tmp/models/assets\n","WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f3a405a7650> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r44875/44875 [==============================] - 229s 5ms/step - loss: 68.2044 - mse: 68.2044 - mae: 6.3042 - val_loss: 75.2146 - val_mse: 75.2146 - val_mae: 6.6331 - lr: 6.2500e-05\n","Epoch 19/50\n","44866/44875 [============================>.] - ETA: 0s - loss: 68.0573 - mse: 68.0573 - mae: 6.2964\n","Epoch 19: val_loss improved from 75.21457 to 74.15583, saving model to tmp/models\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Assets written to: tmp/models/assets\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:Assets written to: tmp/models/assets\n","WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f3a405a7650> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r44875/44875 [==============================] - 227s 5ms/step - loss: 68.0638 - mse: 68.0638 - mae: 6.2968 - val_loss: 74.1558 - val_mse: 74.1558 - val_mae: 6.6032 - lr: 6.2500e-05\n","Epoch 20/50\n","44868/44875 [============================>.] - ETA: 0s - loss: 68.0228 - mse: 68.0228 - mae: 6.2965\n","Epoch 20: val_loss did not improve from 74.15583\n","44875/44875 [==============================] - 222s 5ms/step - loss: 68.0320 - mse: 68.0320 - mae: 6.2969 - val_loss: 75.1944 - val_mse: 75.1944 - val_mae: 6.6320 - lr: 6.2500e-05\n","Epoch 21/50\n","44871/44875 [============================>.] - ETA: 0s - loss: 67.7855 - mse: 67.7855 - mae: 6.2873\n","Epoch 21: val_loss did not improve from 74.15583\n","44875/44875 [==============================] - 224s 5ms/step - loss: 67.7871 - mse: 67.7871 - mae: 6.2874 - val_loss: 75.3061 - val_mse: 75.3061 - val_mae: 6.6380 - lr: 6.2500e-05\n","Epoch 22/50\n","44865/44875 [============================>.] - ETA: 0s - loss: 67.8376 - mse: 67.8376 - mae: 6.2882\n","Epoch 22: val_loss improved from 74.15583 to 73.08415, saving model to tmp/models\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Assets written to: tmp/models/assets\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:Assets written to: tmp/models/assets\n","WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f3a405a7650> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r44875/44875 [==============================] - 229s 5ms/step - loss: 67.8481 - mse: 67.8481 - mae: 6.2887 - val_loss: 73.0842 - val_mse: 73.0842 - val_mae: 6.5655 - lr: 3.1250e-05\n","Epoch 23/50\n","44868/44875 [============================>.] - ETA: 0s - loss: 67.7728 - mse: 67.7728 - mae: 6.2854\n","Epoch 23: val_loss did not improve from 73.08415\n","44875/44875 [==============================] - 223s 5ms/step - loss: 67.7765 - mse: 67.7765 - mae: 6.2856 - val_loss: 74.3549 - val_mse: 74.3549 - val_mae: 6.6077 - lr: 3.1250e-05\n","Epoch 24/50\n","44870/44875 [============================>.] - ETA: 0s - loss: 67.7823 - mse: 67.7823 - mae: 6.2857\n","Epoch 24: val_loss did not improve from 73.08415\n","44875/44875 [==============================] - 225s 5ms/step - loss: 67.7858 - mse: 67.7858 - mae: 6.2859 - val_loss: 73.3960 - val_mse: 73.3960 - val_mae: 6.5770 - lr: 3.1250e-05\n","Epoch 25/50\n","44875/44875 [==============================] - ETA: 0s - loss: 67.7476 - mse: 67.7476 - mae: 6.2826\n","Epoch 25: val_loss did not improve from 73.08415\n","44875/44875 [==============================] - 228s 5ms/step - loss: 67.7476 - mse: 67.7476 - mae: 6.2826 - val_loss: 73.4043 - val_mse: 73.4043 - val_mae: 6.5727 - lr: 1.5625e-05\n","Epoch 26/50\n","44872/44875 [============================>.] - ETA: 0s - loss: 67.7469 - mse: 67.7469 - mae: 6.2843Restoring model weights from the end of the best epoch: 22.\n","\n","Epoch 26: val_loss did not improve from 73.08415\n","44875/44875 [==============================] - 227s 5ms/step - loss: 67.7475 - mse: 67.7475 - mae: 6.2843 - val_loss: 73.4146 - val_mse: 73.4146 - val_mae: 6.5732 - lr: 1.5625e-05\n","Epoch 26: early stopping\n","1/1 [==============================] - 1s 633ms/step - loss: 73.0842 - mse: 73.0842 - mae: 6.5655\n"]}]}]}